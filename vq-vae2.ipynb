{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Schduler","metadata":{}},{"cell_type":"code","source":"from math import cos, pi, floor, sin\n\nfrom torch.optim import lr_scheduler\n\n\nclass CosineLR(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, step_size):\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.step_size = step_size\n        self.iteration = 0\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        lr = self.lr_min + 0.5 * (self.lr_max - self.lr_min) * (\n            1 + cos(self.iteration / self.step_size * pi)\n        )\n        self.iteration += 1\n\n        if self.iteration == self.step_size:\n            self.iteration = 0\n\n        return [lr for base_lr in self.base_lrs]\n\n\nclass PowerLR(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, warmup):\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.warmup = warmup\n        self.iteration = 0\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        if self.iteration < self.warmup:\n            lr = (\n                self.lr_min + (self.lr_max - self.lr_min) / self.warmup * self.iteration\n            )\n\n        else:\n            lr = self.lr_max * (self.iteration - self.warmup + 1) ** -0.5\n\n        self.iteration += 1\n\n        return [lr for base_lr in self.base_lrs]\n\n\nclass SineLR(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, step_size):\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.step_size = step_size\n        self.iteration = 0\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        lr = self.lr_min + (self.lr_max - self.lr_min) * sin(\n            self.iteration / self.step_size * pi\n        )\n        self.iteration += 1\n\n        if self.iteration == self.step_size:\n            self.iteration = 0\n\n        return [lr for base_lr in self.base_lrs]\n\n\nclass LinearLR(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, warmup, step_size):\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.step_size = step_size\n        self.warmup = warmup\n        self.iteration = 0\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        if self.iteration < self.warmup:\n            lr = self.lr_max\n\n        else:\n            lr = self.lr_max + (self.iteration - self.warmup) * (\n                self.lr_min - self.lr_max\n            ) / (self.step_size - self.warmup)\n        self.iteration += 1\n\n        if self.iteration == self.step_size:\n            self.iteration = 0\n\n        return [lr for base_lr in self.base_lrs]\n\n\nclass CLR(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, step_size):\n        self.epoch = 0\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.current_lr = lr_min\n        self.step_size = step_size\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        cycle = floor(1 + self.epoch / (2 * self.step_size))\n        x = abs(self.epoch / self.step_size - 2 * cycle + 1)\n        lr = self.lr_min + (self.lr_max - self.lr_min) * max(0, 1 - x)\n        self.current_lr = lr\n\n        self.epoch += 1\n\n        return [lr for base_lr in self.base_lrs]\n\n\nclass Warmup(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, model_dim, factor=1, warmup=16000):\n        self.optimizer = optimizer\n        self.model_dim = model_dim\n        self.factor = factor\n        self.warmup = warmup\n        self.iteration = 0\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        self.iteration += 1\n        lr = (\n            self.factor\n            * self.model_dim ** (-0.5)\n            * min(self.iteration ** (-0.5), self.iteration * self.warmup ** (-1.5))\n        )\n\n        return [lr for base_lr in self.base_lrs]\n\n\n# Copyright 2019 fastai\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#     http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# Borrowed from https://github.com/fastai/fastai and changed to make it runs like PyTorch lr scheduler\n\n\nclass CycleAnnealScheduler:\n    def __init__(\n        self, optimizer, lr_max, lr_divider, cut_point, step_size, momentum=None\n    ):\n        self.lr_max = lr_max\n        self.lr_divider = lr_divider\n        self.cut_point = step_size // cut_point\n        self.step_size = step_size\n        self.iteration = 0\n        self.cycle_step = int(step_size * (1 - cut_point / 100) / 2)\n        self.momentum = momentum\n        self.optimizer = optimizer\n\n    def get_lr(self):\n        if self.iteration > 2 * self.cycle_step:\n            cut = (self.iteration - 2 * self.cycle_step) / (\n                self.step_size - 2 * self.cycle_step\n            )\n            lr = self.lr_max * (1 + (cut * (1 - 100) / 100)) / self.lr_divider\n\n        elif self.iteration > self.cycle_step:\n            cut = 1 - (self.iteration - self.cycle_step) / self.cycle_step\n            lr = self.lr_max * (1 + cut * (self.lr_divider - 1)) / self.lr_divider\n\n        else:\n            cut = self.iteration / self.cycle_step\n            lr = self.lr_max * (1 + cut * (self.lr_divider - 1)) / self.lr_divider\n\n        return lr\n\n    def get_momentum(self):\n        if self.iteration > 2 * self.cycle_step:\n            momentum = self.momentum[0]\n\n        elif self.iteration > self.cycle_step:\n            cut = 1 - (self.iteration - self.cycle_step) / self.cycle_step\n            momentum = self.momentum[0] + cut * (self.momentum[1] - self.momentum[0])\n\n        else:\n            cut = self.iteration / self.cycle_step\n            momentum = self.momentum[0] + cut * (self.momentum[1] - self.momentum[0])\n\n        return momentum\n\n    def step(self):\n        lr = self.get_lr()\n\n        if self.momentum is not None:\n            momentum = self.get_momentum()\n\n        self.iteration += 1\n\n        if self.iteration == self.step_size:\n            self.iteration = 0\n\n        for group in self.optimizer.param_groups:\n            group['lr'] = lr\n\n            if self.momentum is not None:\n                group['betas'] = (momentum, group['betas'][1])\n\n        return lr\n\n\ndef anneal_linear(start, end, proportion):\n    return start + proportion * (end - start)\n\n\ndef anneal_cos(start, end, proportion):\n    cos_val = cos(pi * proportion) + 1\n\n    return end + (start - end) / 2 * cos_val\n\n\nclass Phase:\n    def __init__(self, start, end, n_iter, anneal_fn):\n        self.start, self.end = start, end\n        self.n_iter = n_iter\n        self.anneal_fn = anneal_fn\n        self.n = 0\n\n    def step(self):\n        self.n += 1\n\n        return self.anneal_fn(self.start, self.end, self.n / self.n_iter)\n\n    def reset(self):\n        self.n = 0\n\n    @property\n    def is_done(self):\n        return self.n >= self.n_iter\n\n\nclass CycleScheduler:\n    def __init__(\n        self,\n        optimizer,\n        lr_max,\n        n_iter,\n        momentum=(0.95, 0.85),\n        divider=25,\n        warmup_proportion=0.3,\n        phase=('linear', 'cos'),\n    ):\n        self.optimizer = optimizer\n\n        phase1 = int(n_iter * warmup_proportion)\n        phase2 = n_iter - phase1\n        lr_min = lr_max / divider\n\n        phase_map = {'linear': anneal_linear, 'cos': anneal_cos}\n\n        self.lr_phase = [\n            Phase(lr_min, lr_max, phase1, phase_map[phase[0]]),\n            Phase(lr_max, lr_min / 1e4, phase2, phase_map[phase[1]]),\n        ]\n\n        self.momentum = momentum\n\n        if momentum is not None:\n            mom1, mom2 = momentum\n            self.momentum_phase = [\n                Phase(mom1, mom2, phase1, phase_map[phase[0]]),\n                Phase(mom2, mom1, phase2, phase_map[phase[1]]),\n            ]\n\n        else:\n            self.momentum_phase = []\n\n        self.phase = 0\n\n    def step(self):\n        lr = self.lr_phase[self.phase].step()\n\n        if self.momentum is not None:\n            momentum = self.momentum_phase[self.phase].step()\n\n        else:\n            momentum = None\n\n        for group in self.optimizer.param_groups:\n            group['lr'] = lr\n\n            if self.momentum is not None:\n                if 'betas' in group:\n                    group['betas'] = (momentum, group['betas'][1])\n\n                else:\n                    group['momentum'] = momentum\n\n        if self.lr_phase[self.phase].is_done:\n            self.phase += 1\n\n        if self.phase >= len(self.lr_phase):\n            for phase in self.lr_phase:\n                phase.reset()\n\n            for phase in self.momentum_phase:\n                phase.reset()\n\n            self.phase = 0\n\n        return lr, momentum\n\n\nclass LRFinder(lr_scheduler._LRScheduler):\n    def __init__(self, optimizer, lr_min, lr_max, step_size, linear=False):\n        ratio = lr_max / lr_min\n        self.linear = linear\n        self.lr_min = lr_min\n        self.lr_mult = (ratio / step_size) if linear else ratio ** (1 / step_size)\n        self.iteration = 0\n        self.lrs = []\n        self.losses = []\n\n        super().__init__(optimizer, -1)\n\n    def get_lr(self):\n        lr = (\n            self.lr_mult * self.iteration\n            if self.linear\n            else self.lr_mult ** self.iteration\n        )\n        lr = self.lr_min + lr if self.linear else self.lr_min * lr\n\n        self.iteration += 1\n        self.lrs.append(lr)\n\n        return [lr for base_lr in self.base_lrs]\n\n    def record(self, loss):\n        self.losses.append(loss)\n\n    def save(self, filename):\n        with open(filename, 'w') as f:\n            for lr, loss in zip(self.lrs, self.losses):\n                f.write('{},{}\\n'.format(lr, loss))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VQVAE","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nimport distributed as dist_fn\n\n\n# Copyright 2018 The Sonnet Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ============================================================================\n\n\n# Borrowed from https://github.com/deepmind/sonnet and ported it to PyTorch\n\n\nclass Quantize(nn.Module):\n    def __init__(self, dim, n_embed, decay=0.99, eps=1e-5):\n        super().__init__()\n\n        self.dim = dim\n        self.n_embed = n_embed\n        self.decay = decay\n        self.eps = eps\n\n        embed = torch.randn(dim, n_embed)\n        self.register_buffer(\"embed\", embed)\n        self.register_buffer(\"cluster_size\", torch.zeros(n_embed))\n        self.register_buffer(\"embed_avg\", embed.clone())\n\n    def forward(self, input):\n        flatten = input.reshape(-1, self.dim)\n        dist = (\n            flatten.pow(2).sum(1, keepdim=True)\n            - 2 * flatten @ self.embed\n            + self.embed.pow(2).sum(0, keepdim=True)\n        )\n        _, embed_ind = (-dist).max(1)\n        embed_onehot = F.one_hot(embed_ind, self.n_embed).type(flatten.dtype)\n        embed_ind = embed_ind.view(*input.shape[:-1])\n        quantize = self.embed_code(embed_ind)\n\n        if self.training:\n            embed_onehot_sum = embed_onehot.sum(0)\n            embed_sum = flatten.transpose(0, 1) @ embed_onehot\n\n            dist_fn.all_reduce(embed_onehot_sum)\n            dist_fn.all_reduce(embed_sum)\n\n            self.cluster_size.data.mul_(self.decay).add_(\n                embed_onehot_sum, alpha=1 - self.decay\n            )\n            self.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)\n            n = self.cluster_size.sum()\n            cluster_size = (\n                (self.cluster_size + self.eps) / (n + self.n_embed * self.eps) * n\n            )\n            embed_normalized = self.embed_avg / cluster_size.unsqueeze(0)\n            self.embed.data.copy_(embed_normalized)\n\n        diff = (quantize.detach() - input).pow(2).mean()\n        quantize = input + (quantize - input).detach()\n\n        return quantize, diff, embed_ind\n\n    def embed_code(self, embed_id):\n        return F.embedding(embed_id, self.embed.transpose(0, 1))\n\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channel, channel):\n        super().__init__()\n\n        self.conv = nn.Sequential(\n            nn.ReLU(),\n            nn.Conv2d(in_channel, channel, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channel, in_channel, 1),\n        )\n\n    def forward(self, input):\n        out = self.conv(input)\n        out += input\n\n        return out\n\n# class HeadAttention(nn.Module):\n#     def __init__(self, channels, size):\n#         super(HeadAttention, self).__init__()\n#         self.channels = channels\n#         self.size = size\n#         self.mha = nn.MultiheadAttention(channels, 3, batch_first=True)\n#         self.ln = nn.LayerNorm([channels])\n#         self.ff_self = nn.Sequential(\n#             nn.LayerNorm([channels]),\n#             nn.Linear(channels, channels),\n#             nn.GELU(),\n#             nn.Linear(channels, channels),\n#         )\n\n#     def forward(self, x):\n#         x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n#         x_ln = self.ln(x)\n#         attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n#         attention_value = attention_value + x\n#         attention_value = self.ff_self(attention_value) + attention_value\n#         return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n\n\nclass Encoder(nn.Module):\n    def __init__(self, in_channel, channel, n_res_block, n_res_channel, stride):\n        super().__init__()\n\n        if stride == 4:\n            blocks = [\n                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(channel // 2, channel, 4, stride=2, padding=1),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(channel, channel, 3, padding=1),\n            ]\n\n        elif stride == 2:\n            blocks = [\n                nn.Conv2d(in_channel, channel // 2, 4, stride=2, padding=1),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(channel // 2, channel, 3, padding=1),\n            ]\n\n        for i in range(n_res_block):\n            blocks.append(ResBlock(channel, n_res_channel))\n\n        blocks.append(nn.ReLU(inplace=True))\n        \n        # if stride == 4:\n        #     blocks.append(HeadAttention(channel, 64))\n        # elif stride == 2:\n        #     blocks.append(HeadAttention(channel, 32))\n\n        self.blocks = nn.Sequential(*blocks)\n\n    def forward(self, input):\n        return self.blocks(input)\n\n\nclass Decoder(nn.Module):\n    def __init__(\n        self, in_channel, out_channel, channel, n_res_block, n_res_channel, stride\n    ):\n        super().__init__()\n\n        blocks = [nn.Conv2d(in_channel, channel, 3, padding=1)]\n\n        for i in range(n_res_block):\n            blocks.append(ResBlock(channel, n_res_channel))\n\n        blocks.append(nn.ReLU(inplace=True))\n    \n        # if stride == 4:\n        #     blocks.append(HeadAttention(channel, 64))\n        # elif stride == 2:\n        #     blocks.append(HeadAttention(channel, 32))\n\n        if stride == 4:\n            blocks.extend(\n                [\n                    nn.ConvTranspose2d(channel, channel // 2, 4, stride=2, padding=1),\n                    nn.ReLU(inplace=True),\n                    nn.ConvTranspose2d(channel // 2, out_channel, 4, stride=2, padding=1),\n                ]\n            )\n\n        elif stride == 2:\n            blocks.append(\n                nn.ConvTranspose2d(channel, out_channel, 4, stride=2, padding=1)\n            )\n\n        self.blocks = nn.Sequential(*blocks)\n\n    def forward(self, input):\n        return self.blocks(input)\n\n\nclass VQVAE(nn.Module):\n    def __init__(\n        self,\n        in_channel=3,\n        channel=128,\n        n_res_block=2,\n        n_res_channel=32,\n        embed_dim=3,\n        n_embed=4096,\n        decay=0.99,\n    ):\n        super().__init__()\n\n        self.enc_b = Encoder(in_channel, channel, n_res_block, n_res_channel, stride=4)\n        self.enc_t = Encoder(channel, channel, n_res_block, n_res_channel, stride=2)\n        self.quantize_conv_t = nn.Conv2d(channel, embed_dim, 1)\n        self.quantize_t = Quantize(embed_dim, n_embed)\n        self.dec_t = Decoder(\n            embed_dim, embed_dim, channel, n_res_block, n_res_channel, stride=2\n        )\n        self.quantize_conv_b = nn.Conv2d(embed_dim + channel, embed_dim, 1)\n        self.quantize_b = Quantize(embed_dim, n_embed)\n        self.upsample_t = nn.ConvTranspose2d(embed_dim, embed_dim, 4, stride=2, padding=1)\n        self.dec = Decoder(\n            embed_dim + embed_dim,\n            in_channel,\n            channel,\n            n_res_block,\n            n_res_channel,\n            stride=4,\n        )\n        self.activation = nn.Tanh()\n\n    def forward(self, input):\n        quant_t, quant_b, diff, _, _ = self.encode(input)\n        dec = self.decode(quant_t, quant_b)\n\n        return self.activation(dec), diff\n\n    def encode(self, input):\n        enc_b = self.enc_b(input)\n        enc_t = self.enc_t(enc_b)\n\n        quant_t = self.quantize_conv_t(enc_t).permute(0, 2, 3, 1)\n        quant_t, diff_t, id_t = self.quantize_t(quant_t)\n        quant_t = quant_t.permute(0, 3, 1, 2)\n        diff_t = diff_t.unsqueeze(0)\n\n        dec_t = self.dec_t(quant_t)\n        enc_b = torch.cat([dec_t, enc_b], 1)\n\n        quant_b = self.quantize_conv_b(enc_b).permute(0, 2, 3, 1)\n        quant_b, diff_b, id_b = self.quantize_b(quant_b)\n        quant_b = quant_b.permute(0, 3, 1, 2)\n        diff_b = diff_b.unsqueeze(0)\n\n        return quant_t, quant_b, diff_t + diff_b, id_t, id_b\n\n    def decode(self, quant_t, quant_b):\n        upsample_t = self.upsample_t(quant_t)\n        quant = torch.cat([upsample_t, quant_b], 1)\n        dec = self.dec(quant)\n\n        return dec\n\n    def decode_code(self, code_t, code_b):\n        quant_t = self.quantize_t.embed_code(code_t)\n        quant_t = quant_t.permute(0, 3, 1, 2)\n        quant_b = self.quantize_b.embed_code(code_b)\n        quant_b = quant_b.permute(0, 3, 1, 2)\n\n        dec = self.decode(quant_t, quant_b)\n\n        return dec","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"import argparse\nimport sys\nimport os\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader\n\nfrom torchvision import datasets, transforms, utils\n\nfrom tqdm import tqdm\n\nimport distributed as dist\n\ntry:\n    import cPickle as pickle\nexcept ModuleNotFoundError:\n    import pickle\n\n\ndef train(epoch, loader, val_loader, model, optimizer, scheduler, device):\n\n    criterion = nn.MSELoss()\n\n    latent_loss_weight = 0.25\n\n    train_losses, val_losses = 0.0, 0.0\n\n    \n    for i, (img, label) in enumerate(loader):\n        model.zero_grad()\n        \n        epoch_loss = 0\n        total_inputs = 0\n\n        img = img.to(device)\n\n        out, latent_loss = model(img)\n        recon_loss = criterion(out, img)\n        latent_loss = latent_loss.mean()\n        loss = recon_loss + latent_loss_weight * latent_loss\n        loss.backward()\n\n        if scheduler is not None:\n            scheduler.step()\n        optimizer.step()\n        \n        epoch_loss += loss.item()*len(img)\n\n        total_inputs += len(img)\n\n\n        if i%100 == 0:\n            print(\"Train loss: \", loss.item())\n            print(\"MSE loss: \", recon_loss.item())\n            print()\n\n\n    train_losses = (epoch_loss / total_inputs)\n\n\n\n    epoch_loss = 0\n    total_inputs = 0\n\n    with torch.no_grad():\n\n        for data in val_loader:\n\n            inputs, _ = data\n            inputs = inputs.to(device)\n\n            outputs, latent_loss = model(inputs)\n            mse = criterion(outputs, inputs)\n            loss = mse + latent_loss * latent_loss_weight\n\n\n            epoch_loss += loss.item()*len(inputs)\n            total_inputs += len(inputs)\n\n        val_losses = (epoch_loss / total_inputs)\n\n    print(\"Epoch {}:\".format(epoch))\n    print(\"Train loss: \", train_losses)\n    print(\"Validation loss: \", val_losses)\n\n    model.train()\n\n    return train_losses, val_losses\n\n\ndef main(args):\n    device = \"cuda\"\n\n    train_losses, val_losses = [], []\n\n    args.distributed = dist.get_world_size() > 1\n\n    transform = transforms.Compose([\n        transforms.Lambda(lambda img: transforms.Resize(args.size)(img) if min(img.size) < args.size \n                          else (transforms.Resize(2*args.size)(img) if max(img.size) >= 2*args.size else img)),\n        transforms.ColorJitter(brightness=0.4, contrast=0.7, saturation=0.5, hue=0.5),\n        transforms.RandomCrop(args.size),\n        transforms.RandomHorizontalFlip(0.5),\n        transforms.RandomVerticalFlip(0.5),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n    ])\n\n    dataset = datasets.ImageFolder(args.path_train, transform=transform)\n    sampler = dist.data_sampler(dataset, shuffle=True, distributed=args.distributed)\n    loader = DataLoader(\n        dataset, batch_size=100 // args.n_gpu, sampler=sampler, num_workers=2\n    )\n    \n    dataset_val = datasets.ImageFolder(args.path_val, transform=transform)\n    sampler_val = dist.data_sampler(dataset_val, shuffle=False, distributed=args.distributed)\n    loader_val = DataLoader(\n        dataset, batch_size=100 // args.n_gpu, sampler=sampler_val, num_workers=2\n    )\n\n    model = VQVAE().to(device)\n\n    if args.distributed:\n        model = nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[dist.get_local_rank()],\n            output_device=dist.get_local_rank(),\n        )\n\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n    scheduler = None\n    if args.sched == \"cycle\":\n        scheduler = CycleScheduler(\n            optimizer,\n            args.lr,\n            n_iter=len(loader) * args.epoch,\n            momentum=None,\n            warmup_proportion=0.05,\n        )\n\n    start_epoch = 0\n    #################################################\n    ## load checkpoint\n    # checkpoint = torch.load('G3/vqvae_002.pth')\n    # model.load_state_dict(checkpoint['model_state_dict'])\n    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    # with open(\"G3/vqvae_sch_2.pkl\", \"rb\") as file:\n    #   schedduler = pickle.load(file)\n    # start_epoch = checkpoint['epoch']\n    ###################################################\n    \n    for i in range(start_epoch + 1, args.epoch + 1):\n        t_loss, v_loss = train(i, loader, loader_val, model, optimizer, scheduler, device)\n\n        train_losses.append(t_loss)\n        val_losses.append(v_loss)\n\n        if dist.is_primary():\n            torch.save({\n              'epoch': i,\n              'model_state_dict': model.state_dict(),\n              'optimizer_state_dict': optimizer.state_dict(),\n              'train_loss': train_losses,\n              'val_loss': val_losses,\n            }, f\"vqvae_{str(i).zfill(3)}.pth\")\n            with open(f\"vqvae_sch_{str(i)}.pkl\", \"wb\") as file:\n                pickle.dump(scheduler, file, -1)\n\n\n# if __name__ == \"__main__\":\n        \nparser = argparse.ArgumentParser()\nparser.add_argument(\"--n_gpu\", type=int, default=2)\n\nport = (\n    2 ** 15\n    + 2 ** 14\n    + hash(os.getuid() if sys.platform != \"win32\" else 1) % 2 ** 14\n)\nparser.add_argument(\"--dist_url\", default=f\"tcp://127.0.0.1:{port}\")\n\nparser.add_argument(\"--size\", type=int, default=256)\nparser.add_argument(\"--epoch\", type=int, default=30)\nparser.add_argument(\"--lr\", type=float, default=15e-4)\nparser.add_argument(\"--sched\", type=str, default='cycle')\nparser.add_argument(\"--path_train\", type=str, default='/kaggle/input/abstract-37k/Abstract-jpg/Train')\nparser.add_argument(\"--path_val\", type=str, default='/kaggle/input/abstract-37k/Abstract-jpg/Validation')\n\nargs = parser.parse_args()\n\nprint(args)\n\ndist.launch(main, args.n_gpu, 1, 0, args.dist_url, args=(args,))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}