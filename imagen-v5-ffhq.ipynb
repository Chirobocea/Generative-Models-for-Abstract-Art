{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05f0cab",
   "metadata": {
    "id": "8HWT6O_nyDXf",
    "papermill": {
     "duration": 0.007841,
     "end_time": "2023-05-22T10:21:00.397436",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.389595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ec29ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.409764Z",
     "iopub.status.busy": "2023-05-22T10:21:00.409417Z",
     "iopub.status.idle": "2023-05-22T10:21:00.414236Z",
     "shell.execute_reply": "2023-05-22T10:21:00.413410Z"
    },
    "id": "M-etnuVJ0ALk",
    "papermill": {
     "duration": 0.014916,
     "end_time": "2023-05-22T10:21:00.417941",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.403025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62630a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.430008Z",
     "iopub.status.busy": "2023-05-22T10:21:00.429395Z",
     "iopub.status.idle": "2023-05-22T10:21:00.433426Z",
     "shell.execute_reply": "2023-05-22T10:21:00.432625Z"
    },
    "id": "aHRjj8e7dq-4",
    "papermill": {
     "duration": 0.011981,
     "end_time": "2023-05-22T10:21:00.435333",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.423352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9461c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.447048Z",
     "iopub.status.busy": "2023-05-22T10:21:00.446803Z",
     "iopub.status.idle": "2023-05-22T10:21:00.450174Z",
     "shell.execute_reply": "2023-05-22T10:21:00.449328Z"
    },
    "id": "K8EsqExv0DnY",
    "papermill": {
     "duration": 0.011796,
     "end_time": "2023-05-22T10:21:00.452466",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.440670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4786ddcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.465920Z",
     "iopub.status.busy": "2023-05-22T10:21:00.464298Z",
     "iopub.status.idle": "2023-05-22T10:21:00.468851Z",
     "shell.execute_reply": "2023-05-22T10:21:00.468032Z"
    },
    "id": "yDC2td0a0FVt",
    "papermill": {
     "duration": 0.012702,
     "end_time": "2023-05-22T10:21:00.470719",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.458017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "  # !kaggle datasets download -d mihailchirobocea/ffhq-64-train-50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810e6652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.483093Z",
     "iopub.status.busy": "2023-05-22T10:21:00.482365Z",
     "iopub.status.idle": "2023-05-22T10:21:00.486248Z",
     "shell.execute_reply": "2023-05-22T10:21:00.485467Z"
    },
    "id": "B9vBIqes0GxC",
    "papermill": {
     "duration": 0.01187,
     "end_time": "2023-05-22T10:21:00.488183",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.476313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /content/ffhq-64-train-50k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8b06f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:00.500932Z",
     "iopub.status.busy": "2023-05-22T10:21:00.500235Z",
     "iopub.status.idle": "2023-05-22T10:21:04.152589Z",
     "shell.execute_reply": "2023-05-22T10:21:04.151588Z"
    },
    "id": "Vu19zKKUyDXh",
    "papermill": {
     "duration": 3.661116,
     "end_time": "2023-05-22T10:21:04.154946",
     "exception": false,
     "start_time": "2023-05-22T10:21:00.493830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6fc59",
   "metadata": {
    "id": "pSawGh1wyDXi",
    "papermill": {
     "duration": 0.005231,
     "end_time": "2023-05-22T10:21:04.166047",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.160816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba07b0fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:04.178867Z",
     "iopub.status.busy": "2023-05-22T10:21:04.177873Z",
     "iopub.status.idle": "2023-05-22T10:21:04.186875Z",
     "shell.execute_reply": "2023-05-22T10:21:04.186119Z"
    },
    "id": "jpa4t4wCyDXi",
    "papermill": {
     "duration": 0.017416,
     "end_time": "2023-05-22T10:21:04.188929",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.171513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(torch.cat([torch.cat([i for i in images.cpu()], dim=-1),], dim=-2).permute(1, 2, 0).cpu())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_images(images, path, **kwargs):\n",
    "    grid = torchvision.utils.make_grid(images, **kwargs)\n",
    "    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    im.save(path)\n",
    "\n",
    "\n",
    "def get_data(args):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        # transforms.Lambda(lambda img: transforms.Resize(args.image_size)(img) if min(img.size) < args.image_size \n",
    "        #                   else (transforms.Resize(2*args.image_size)(img) if max(img.size) >= 2*args.image_size else img)),\n",
    "        # transforms.RandomCrop(args.image_size),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        # transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset = torchvision.datasets.ImageFolder(args.dataset_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d3bde",
   "metadata": {
    "id": "fXDOUoJtz4EH",
    "papermill": {
     "duration": 0.005096,
     "end_time": "2023-05-22T10:21:04.199827",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.194731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Rate Schduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d57de6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:04.211952Z",
     "iopub.status.busy": "2023-05-22T10:21:04.211660Z",
     "iopub.status.idle": "2023-05-22T10:21:04.227534Z",
     "shell.execute_reply": "2023-05-22T10:21:04.226691Z"
    },
    "id": "hhWNjbaVz4EI",
    "papermill": {
     "duration": 0.024331,
     "end_time": "2023-05-22T10:21:04.229517",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.205186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import cos, pi, floor, sin\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def anneal_linear(start, end, proportion):\n",
    "    return start + proportion * (end - start)\n",
    "\n",
    "\n",
    "def anneal_cos(start, end, proportion):\n",
    "    cos_val = cos(pi * proportion) + 1\n",
    "\n",
    "    return end + (start - end) / 2 * cos_val\n",
    "\n",
    "\n",
    "class Phase:\n",
    "    def __init__(self, start, end, n_iter, anneal_fn):\n",
    "        self.start, self.end = start, end\n",
    "        self.n_iter = n_iter\n",
    "        self.anneal_fn = anneal_fn\n",
    "        self.n = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "\n",
    "        return self.anneal_fn(self.start, self.end, self.n / self.n_iter)\n",
    "\n",
    "    def reset(self):\n",
    "        self.n = 0\n",
    "\n",
    "    @property\n",
    "    def is_done(self):\n",
    "        return self.n >= self.n_iter\n",
    "\n",
    "\n",
    "class CycleScheduler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer,\n",
    "        lr_max,\n",
    "        n_iter,\n",
    "        momentum=(0.95, 0.85),\n",
    "        divider=25,\n",
    "        warmup_proportion=0.1,\n",
    "        phase=('linear', 'cos'),\n",
    "    ):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        phase1 = int(n_iter * warmup_proportion)\n",
    "        phase2 = n_iter - phase1\n",
    "        lr_min = lr_max / divider\n",
    "\n",
    "        phase_map = {'linear': anneal_linear, 'cos': anneal_cos}\n",
    "\n",
    "        self.lr_phase = [\n",
    "            Phase(lr_min, lr_max, phase1, phase_map[phase[0]]),\n",
    "            Phase(lr_max, lr_min / 1e4, phase2, phase_map[phase[1]]),\n",
    "        ]\n",
    "\n",
    "        self.momentum = momentum\n",
    "\n",
    "        if momentum is not None:\n",
    "            mom1, mom2 = momentum\n",
    "            self.momentum_phase = [\n",
    "                Phase(mom1, mom2, phase1, phase_map[phase[0]]),\n",
    "                Phase(mom2, mom1, phase2, phase_map[phase[1]]),\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            self.momentum_phase = []\n",
    "\n",
    "        self.phase = 0\n",
    "\n",
    "    def step(self):\n",
    "        lr = self.lr_phase[self.phase].step()\n",
    "\n",
    "        if self.momentum is not None:\n",
    "            momentum = self.momentum_phase[self.phase].step()\n",
    "\n",
    "        else:\n",
    "            momentum = None\n",
    "\n",
    "        for group in self.optimizer.param_groups:\n",
    "            group['lr'] = lr\n",
    "\n",
    "            if self.momentum is not None:\n",
    "                if 'betas' in group:\n",
    "                    group['betas'] = (momentum, group['betas'][1])\n",
    "\n",
    "                else:\n",
    "                    group['momentum'] = momentum\n",
    "\n",
    "        if self.lr_phase[self.phase].is_done:\n",
    "            self.phase += 1\n",
    "\n",
    "        if self.phase >= len(self.lr_phase):\n",
    "            for phase in self.lr_phase:\n",
    "                phase.reset()\n",
    "\n",
    "            for phase in self.momentum_phase:\n",
    "                phase.reset()\n",
    "\n",
    "            self.phase = 0\n",
    "\n",
    "        return lr, momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55400a",
   "metadata": {
    "id": "A8cklcEmyDXj",
    "papermill": {
     "duration": 0.005092,
     "end_time": "2023-05-22T10:21:04.240183",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.235091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900b3a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:04.252463Z",
     "iopub.status.busy": "2023-05-22T10:21:04.252177Z",
     "iopub.status.idle": "2023-05-22T10:21:04.300785Z",
     "shell.execute_reply": "2023-05-22T10:21:04.300005Z"
    },
    "id": "tj5KIsCfyDXj",
    "papermill": {
     "duration": 0.057252,
     "end_time": "2023-05-22T10:21:04.302776",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.245524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EMA():\n",
    "    def __init__(self, beta, step = 0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.step = step\n",
    "\n",
    "    def update_model_average(self, ema_model, current_model):\n",
    "        for current_params, ema_params in zip(current_model.parameters(), ema_model.parameters()):\n",
    "            old_weight, up_weight = ema_params.data, current_params.data\n",
    "            ema_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "    def step_ema(self, ema_model, model, step_start_ema=2000):\n",
    "        if self.step < step_start_ema:\n",
    "            self.reset_parameters(ema_model, model)\n",
    "            self.step += 1\n",
    "            return\n",
    "        self.update_model_average(ema_model, model)\n",
    "        self.step += 1\n",
    "\n",
    "    def reset_parameters(self, ema_model, model):\n",
    "        ema_model.load_state_dict(model.state_dict())\n",
    "        \n",
    "        \n",
    "\n",
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(HeadAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        x = x.view(-1, self.channels, h * w).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, h, w)\n",
    "    \n",
    "\n",
    "\n",
    "class SkipAttention(nn.Module):\n",
    "    def __init__(self, f_in_g, f_in_x, f_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_g = nn.Sequential(\n",
    "            nn.Conv2d(f_in_g, f_out, kernel_size = 1, stride = 1, padding = 0),\n",
    "            nn.BatchNorm2d(f_out)\n",
    "        )\n",
    "        \n",
    "        self.w_x = nn.Sequential(\n",
    "            nn.Conv2d(f_in_x, f_out, kernel_size = 1, stride = 1, padding = 0),\n",
    "            nn.BatchNorm2d(f_out)\n",
    "        )\n",
    "\n",
    "        # self.g_up = nn.ConvTranspose2d(f_out, f_out, 4, stride=2, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(f_out, 1, kernel_size = 1, stride = 1, padding = 0),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "         \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.w_g(g)\n",
    "        x1 = self.w_x(x)\n",
    "        # g1 = self.g_up(g1)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        return psi*x\n",
    "    \n",
    "    \n",
    "    \n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False, emb_dim=512):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "        \n",
    "        self.emb_layer = nn.Linear(emb_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, t = None):\n",
    "        if self.residual:\n",
    "            x = F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            x = self.double_conv(x)\n",
    "        if t is not None:\n",
    "            emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "            x = x + emb\n",
    "        return x\n",
    "    \n",
    "        \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down = nn.Conv2d(in_channels, in_channels, 4, stride=2, padding=1)\n",
    "        \n",
    "        self.conv1 = DoubleConv(in_channels, in_channels, residual=True)\n",
    "        self.conv2 = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "        self.emb_layer = nn.Linear(emb_dim, out_channels)\n",
    "\n",
    "        self.head_attention = HeadAttention(out_channels)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.down(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        x = x + emb\n",
    "        x = self.head_attention(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, gated_attention, emb_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gated_attention = gated_attention\n",
    "\n",
    "        self.attention = SkipAttention(in_channels // 2, in_channels // 2, in_channels // 2)\n",
    "\n",
    "        self.conv1 = DoubleConv(in_channels, in_channels, residual=True)\n",
    "        self.conv2 = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(out_channels, out_channels, 4, stride=2, padding=1)\n",
    "\n",
    "        self.emb_layer = nn.Linear(emb_dim, out_channels)\n",
    "        \n",
    "        self.head_attention = HeadAttention(out_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        \n",
    "        if self.gated_attention:\n",
    "            skip_x = self.attention(g=x, x=skip_x)\n",
    "        \n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        x = x + emb\n",
    "        x = self.head_attention(x)\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class In(nn.Module):\n",
    "    def __init__(self, out_channels, in_channels = 3, emb_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.conv2 = DoubleConv(out_channels, out_channels, residual = True)\n",
    "\n",
    "        self.emb_layer = nn.Linear(emb_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        x = x + emb\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Out(nn.Module):\n",
    "    def __init__(self, in_channels, gated_attention, out_channels = 3, emb_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gated_attention = gated_attention\n",
    "\n",
    "        self.attention = SkipAttention(in_channels // 2, in_channels // 2, in_channels // 2)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual = True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x):\n",
    "        \n",
    "        if self.gated_attention:\n",
    "            skip_x = self.attention(g=x, x=skip_x)\n",
    "        \n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, device, gated_attention = False, c_in=3, c_out=3, time_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = [128 * k for k in range(1,5)]\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        # self.time_embed = nn.Sequential(\n",
    "        #     nn.Linear(time_dim, time_dim),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Linear(time_dim, time_dim),\n",
    "        #     nn.GELU(),\n",
    "        # )\n",
    "\n",
    "        self.inc = In(self.channels[0])\n",
    "        \n",
    "        self.down1 = Down(self.channels[0], self.channels[1])\n",
    "        self.down2 = Down(self.channels[1], self.channels[2])\n",
    "        self.down3 = Down(self.channels[2], self.channels[3])\n",
    "\n",
    "        self.bot1 = DoubleConv(self.channels[3], self.channels[3], residual = True)\n",
    "        self.bot2 = DoubleConv(self.channels[3], self.channels[3], residual = True)\n",
    "        self.bot3 = DoubleConv(self.channels[3], self.channels[3], residual = True)\n",
    "        self.bot4 = DoubleConv(self.channels[3], self.channels[3], residual = True)\n",
    "        self.bot5 = DoubleConv(self.channels[3], self.channels[3], residual = True)\n",
    "\n",
    "        self.up1 = Up(2*self.channels[3], self.channels[2], gated_attention)\n",
    "        self.up2 = Up(2*self.channels[2], self.channels[1], gated_attention)\n",
    "        self.up3 = Up(2*self.channels[1], self.channels[0], gated_attention)\n",
    "\n",
    "        self.outc = Out(2*self.channels[0], gated_attention)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2, device=self.device).float() / channels))\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "        # t = self.time_embed(t)\n",
    "\n",
    "        x1 = self.inc(x, t)\n",
    "        x2 = self.down1(x1, t)\n",
    "        x3 = self.down2(x2, t)\n",
    "        x4 = self.down3(x3, t)\n",
    "\n",
    "        x5 = self.bot1(x4, t = t)\n",
    "        x5 = self.bot2(x5, t = t)\n",
    "        x5 = self.bot3(x5, t = t)\n",
    "        x5 = self.bot4(x5, t = t)\n",
    "        x5 = self.bot5(x5, t = t)\n",
    "\n",
    "        x = self.up1(x5, x4, t)\n",
    "        x = self.up2(x, x3, t)\n",
    "        x = self.up3(x, x2, t)\n",
    "        x = self.outc(x, x1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db3c6a",
   "metadata": {
    "id": "Fg1gUMotyDXm",
    "papermill": {
     "duration": 0.00537,
     "end_time": "2023-05-22T10:21:04.313510",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.308140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b855a5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:04.325665Z",
     "iopub.status.busy": "2023-05-22T10:21:04.325410Z",
     "iopub.status.idle": "2023-05-22T10:21:04.417762Z",
     "shell.execute_reply": "2023-05-22T10:21:04.416926Z"
    },
    "id": "HsiYpM8byDXm",
    "papermill": {
     "duration": 0.100989,
     "end_time": "2023-05-22T10:21:04.419831",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.318842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, config):\n",
    "        self.img_size = config.generate_img_size\n",
    "        self.noise_steps = config.noise_steps\n",
    "        self.device = config.device\n",
    "        self.img_size = config.generate_img_size\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule(schedule=config.schedule, noise_steps=self.noise_steps).to(self.device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_noise_schedule(schedule, noise_steps, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "\n",
    "        if schedule == \"linear\":\n",
    "            betas = torch.linspace(linear_start, linear_end, noise_steps)\n",
    "\n",
    "        # https://github.com/lucidrains/denoising-diffusion-pytorch/blob/main/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py\n",
    "        elif schedule == \"cosine\":\n",
    "            timesteps = (torch.arange(noise_steps + 1) / noise_steps + cosine_s)\n",
    "            alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "            alphas = torch.cos(alphas).pow(2)\n",
    "            alphas = alphas / alphas[0]\n",
    "            betas = 1 - alphas[1:] / alphas[:-1]\n",
    "            betas = betas.clamp(max=0.999)\n",
    "\n",
    "        return betas\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, title, model, n, epoch):\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
    "        for i in reversed(range(1, self.noise_steps)):\n",
    "            t = (torch.ones(n) * i).long().to(self.device)\n",
    "            predicted_noise = model(x, t)\n",
    "            alpha = self.alpha[t][:, None, None, None]\n",
    "            alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "            beta = self.beta[t][:, None, None, None]\n",
    "            if i > 1:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x)\n",
    "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "\n",
    "        save_images(x, f\"sample{epoch}_{title}.jpg\")\n",
    "        plot_images(x)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def train(config, path = None, scheduler_path = None):\n",
    "    \n",
    "    dataloader = get_data(config)\n",
    "    print(\"loaded\")\n",
    "    \n",
    "    model = UNet(config.device, config.gated_attention).to(config.device)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr)\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    if config.sched == \"cycle\" and scheduler_path == None:\n",
    "        print(\"sch\")\n",
    "        scheduler = CycleScheduler(\n",
    "            optimizer,\n",
    "            config.lr,\n",
    "            n_iter= len(dataloader) * config.epochs,\n",
    "        )\n",
    "    \n",
    "    losses = []\n",
    "    start_epoch = 0\n",
    "    \n",
    "    if path is not None:\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        config_dict = checkpoint[\"config\"]\n",
    "        config.__dict__.update(config_dict)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        losses = checkpoint['loss']\n",
    "        if config.sched == \"cycle\" and scheduler_path is not None:\n",
    "            with open(scheduler_path, \"rb\") as file:\n",
    "                scheduler = pickle.load(file)\n",
    "            scheduler.optimizer = optimizer\n",
    "        \n",
    "        steps_ema = len(dataloader)*start_epoch\n",
    "        ema = EMA(0.995, steps_ema)\n",
    "        ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "        ema_model.load_state_dict(checkpoint['ema_model_state_dict'])\n",
    "        \n",
    "        del checkpoint\n",
    "        del config_dict\n",
    "        \n",
    "    else:\n",
    "        ema = EMA(0.995)\n",
    "        ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "        \n",
    "    \n",
    "    diffusion = Diffusion(config)\n",
    "\n",
    " \n",
    "    if config.mix_precision:\n",
    "        scaler = GradScaler()\n",
    "\n",
    "    for epoch in range(start_epoch+1, 51):\n",
    "        \n",
    "        epoch_loss = []\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        for k, (images, _) in enumerate(tqdm(dataloader)):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images = images.to(config.device)\n",
    "            \n",
    "            if config.mix_precision:\n",
    "                with autocast():\n",
    "                    t = diffusion.sample_timesteps(images.shape[0]).to(config.device)\n",
    "                    x_t, noise = diffusion.noise_images(images, t)\n",
    "                    predicted_noise = model(x_t, t)\n",
    "                    loss = mse(noise, predicted_noise)           \n",
    "                scaler.scale(loss).backward()\n",
    "                if config.sched == \"cycle\":\n",
    "                    scheduler.step()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                ema.step_ema(ema_model, model)\n",
    "            else:\n",
    "                t = diffusion.sample_timesteps(images.shape[0]).to(config.device)\n",
    "                x_t, noise = diffusion.noise_images(images, t)\n",
    "                predicted_noise = model(x_t, t)\n",
    "                loss = mse(noise, predicted_noise)           \n",
    "                loss.backward()\n",
    "                if config.sched == \"cycle\":\n",
    "                    scheduler.step()\n",
    "                optimizer.step()\n",
    "                ema.step_ema(ema_model, model)\n",
    "            \n",
    "\n",
    "            if k%100 == 0:\n",
    "                print(f\"e{epoch}  |  b{k}  |  MSE {loss.item()}  |  Lr {optimizer.param_groups[0]['lr']}  |  t {t}\")\n",
    "                \n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "        epoch_loss = np.array(epoch_loss).mean()\n",
    "        print(f\"Epoch {epoch} loss: {epoch_loss}\")\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "        if epoch%5 == 0 or epoch > 70:\n",
    "\n",
    "            path = f'my_diff_ffhq_v5_e{str(epoch)}.pth'\n",
    "\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.module.state_dict(),\n",
    "                        'ema_model_state_dict': ema_model.module.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': losses,\n",
    "                        'config': config.__dict__\n",
    "                        }, path)\n",
    "            else:\n",
    "                torch.save({\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'ema_model_state_dict': ema_model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': losses,\n",
    "                        'config': config.__dict__\n",
    "                        }, path)\n",
    "                \n",
    "            if config.sched == \"cycle\":\n",
    "                with open(f\"diff_v5_ffhq_sch_e{str(epoch)}.pkl\", \"wb\") as file:\n",
    "                    pickle.dump(scheduler, file, -1)\n",
    "\n",
    "\n",
    "    \n",
    "class ModelConfig:\n",
    "    def __init__(self, batch_size=10, image_size=64, epochs=100, lr=1e-4, \n",
    "                 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                 mix_precision = False,\n",
    "                 gated_attention = True,\n",
    "                 schedule = 'linear',\n",
    "                 noise_steps = 1000,\n",
    "                 generate_img_size = 64,\n",
    "                 sched = None,\n",
    "                 dataset_path = \"/kaggle/input/ffhq-64-train-50k/Train\"):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.mix_precision = mix_precision\n",
    "        self.gated_attention = gated_attention\n",
    "        self.schedule = schedule\n",
    "        self.noise_steps = noise_steps\n",
    "        self.generate_img_size = generate_img_size\n",
    "        self.sched = sched\n",
    "        self.dataset_path = dataset_path\n",
    "\n",
    "def launch(path = None, sched_path = None):\n",
    "    config = ModelConfig()\n",
    "    train(config, path, sched_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7592db1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:04.432254Z",
     "iopub.status.busy": "2023-05-22T10:21:04.431401Z",
     "iopub.status.idle": "2023-05-22T10:21:05.453993Z",
     "shell.execute_reply": "2023-05-22T10:21:05.451314Z"
    },
    "id": "-ua8YBUZz4EQ",
    "outputId": "bfddbb5b-1eb2-4828-d33b-c1c95e1c7f78",
    "papermill": {
     "duration": 1.030883,
     "end_time": "2023-05-22T10:21:05.456099",
     "exception": false,
     "start_time": "2023-05-22T10:21:04.425216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96328847\n"
     ]
    }
   ],
   "source": [
    "net = UNet(device=\"cpu\", gated_attention = True)\n",
    "print(sum([p.numel() for p in net.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "429fed3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:05.468921Z",
     "iopub.status.busy": "2023-05-22T10:21:05.468636Z",
     "iopub.status.idle": "2023-05-22T10:21:06.460732Z",
     "shell.execute_reply": "2023-05-22T10:21:06.459690Z"
    },
    "id": "QH1PnAeYz4ES",
    "outputId": "4cf935cf-ce42-4bd8-e201-26eb8777be08",
    "papermill": {
     "duration": 1.001124,
     "end_time": "2023-05-22T10:21:06.463018",
     "exception": false,
     "start_time": "2023-05-22T10:21:05.461894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 22 10:21:06 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    27W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b88f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T10:21:06.476271Z",
     "iopub.status.busy": "2023-05-22T10:21:06.475942Z",
     "iopub.status.idle": "2023-05-22T10:24:50.234122Z",
     "shell.execute_reply": "2023-05-22T10:24:50.233241Z"
    },
    "id": "dEDAYZQFyDXm",
    "outputId": "ca1cdb7c-e80f-467a-bc5d-3f837564323a",
    "papermill": {
     "duration": 223.767779,
     "end_time": "2023-05-22T10:24:50.236590",
     "exception": false,
     "start_time": "2023-05-22T10:21:06.468811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "launch(\"/kaggle/input/ffhq-checkpoints/my_diff_ffhq_v5_e50.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 242.740332,
   "end_time": "2023-05-22T10:24:52.609670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-22T10:20:49.869338",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
